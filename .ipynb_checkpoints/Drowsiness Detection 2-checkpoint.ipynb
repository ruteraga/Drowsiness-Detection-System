{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "556ca9b6-4ef4-437f-8026-2eac9dccdc35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import face_recognition\n",
    "from scipy.spatial import distance \n",
    "import math\n",
    "from imutils import face_utils\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import winsound\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3ce94d-dd7a-46d0-b16b-3163adcbd650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "model = joblib.load('knn_model2.pkl')\n",
    "frequency=2500\n",
    "duration=1500\n",
    "# Define labels\n",
    "labels = {0: 'no_yawn', 1: 'yawn'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36610b65-9012-409b-b116-ee488aedab81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using a pre-trained model to extract face landmarks\n",
    "p = \"shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f86eb87-ee82-4bd1-8eab-375dea411dea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Defining function to get mouth_aspect_ratio: mar\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    A = distance.euclidean(mouth[14], mouth[18])\n",
    "    C = distance.euclidean(mouth[12], mouth[16])\n",
    "    mar = (A ) / (C)\n",
    "    return mar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f42d7466-fa01-4d5d-a680-d299fed91ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model(landmarks):\n",
    "\n",
    "    features = pd.DataFrame(columns=[\"MAR\"])\n",
    "    #features = pd.DataFrame(columns=[\"EAR\",\"MAR\",\"Circularity\",\"MOE\"])\n",
    "    #features=[]\n",
    "    eye = landmarks[36:68]\n",
    "    mar = mouth_aspect_ratio(eye)\n",
    "    #mouth_eye = mouth_over_eye(eye)\n",
    "\n",
    "    #new_row={\"EAR\":ear,\"MAR\":mar,\"Circularity\":cir,\"MOE\":mouth_eye}\n",
    "    #features.append([ear, mar, cir, mouth_eye])\n",
    "    #features = np.array(features)\n",
    "    #new_row = ({\"EAR\":ear,\"MAR\": mar,\"Circularity\": cir,\"MOE\": mouth_eye})\n",
    "    new_row = ({\"MAR\": mar})\n",
    "    features.loc[len(features)] = new_row\n",
    "    df=np.asarray(features)\n",
    "    #features.loc[len(features)] = new_row\n",
    "    model = joblib.load('knn_model2.pkl')\n",
    "    Result = model.predict(df)\n",
    "    label_index=np.argmax(Result)\n",
    "    label=labels[label_index]\n",
    "    Result_String = label\n",
    "    \n",
    "\n",
    "    return Result_String, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e407a675-432a-43d4-a115-18aa1bc14095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open video capture\n",
    "#result=[]\n",
    "cap = cv2.VideoCapture(0)  # You can replace '0' with the path to your video file\n",
    "j=0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    #face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haar_face_detection.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    rects=detector(frame, 0)\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        Result_String, features = model(shape)\n",
    "        cv2.putText(frame, f'{Result_String}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        #data.append (features)\n",
    "        #result.append(Result_String)\n",
    "        # Draw on our image, all the finded cordinate points (x,y) \n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)\n",
    "\n",
    "        # Show the image\n",
    "    cv2.imshow(\"Drowsiness Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714f8053-c2cc-47ce-9196-56ef6f109c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
